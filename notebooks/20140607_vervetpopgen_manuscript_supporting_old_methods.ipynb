{
 "metadata": {
  "name": "",
  "signature": "sha256:c149aea86139626bed6317d27078ece02fa4f3f391e89d98f1743e15148bf821"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "These supporting methods are outdated. We keep them here for reference \n",
      "and in case some of the code needs to be reused.\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parallel\n",
      "from IPython.parallel import Client\n",
      "rc = Client(profile=\"default\")\n",
      "dview = rc[:] # use all engines\n",
      "lv = rc.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "#Global init\n",
      "import os, json\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy\n",
      "import pickle\n",
      "#from numpy import *\n",
      "import matplotlib as mpl\n",
      "from matplotlib import pyplot as plt\n",
      "from collections import OrderedDict as odict\n",
      "import itertools as it\n",
      "mpl.rcParams[\"font.size\"]=14\n",
      "eu = os.path.expanduser\n",
      "jn = os.path.join\n",
      "meta_dir = eu(\"~/vervet_project/metadata\")\n",
      "var_ana_dir = eu(\"~/vervet_project/analyses/20140403_UnifiedGenotyper_ref3500_non_VRC/_data\")\n",
      "manuscript_dir = eu(\"~/vervet_project/manuscript/163_pop_manuscript/\")\n",
      "man_ana_dir = eu(\"~/vervet_project/analyses/20140607_vervetpopgen_manuscript/_data\")\n",
      "sweepfinder_dir = eu(\"~/vervet_project/analyses/20140611_163_subpop_sweepfinder/\"\n",
      "                             \"_data/\")\n",
      "assoc_dir = eu(\"~/vervet_project/data/gene_associations\")\n",
      "pops = [\"aet\",\"cyn\",\"pyn\",\"pys\",\"sab\",\"tan\"]\n",
      "colors = [\"blue\",\"magenta\",\"cyan\",\"green\",\"orange\",\"red\"]\n",
      "pops2 = [\"aet\",\"cyn\",\"pyn\",\"pys\",\"sab\",\"sac\",\"tan\"]\n",
      "colors2 = [\"blue\",\"magenta\",\"cyan\",\"green\",\"orange\",\"yellow\",\"red\"]\n",
      "pops3 = [\"aet\",\"cyn\",\"pyn\",\"pys\",\"sab\",\"sac\",\"sar\",\"tan\"]\n",
      "colors2 = [\"blue\",\"magenta\",\"cyan\",\"green\",\"orange\",\"yellow\",\"brown\",\"red\"]\n",
      "#alternative colors, are those better?\n",
      "#colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k'] #=mpl.rcParams['axes.color_cycle'][:7]\n",
      "meta_df = pd.read_csv(jn(meta_dir,\"163_population_ucla_id_taxon.csv\"),index_col=0)\n",
      "meta_df[\"index\"] = meta_df.index\n",
      "if float(\".\".join(pd.__version__.split(\".\")[0:2])) >= 0.14:\n",
      "    meta_df.drop_duplicates(subset='index', take_last=True, inplace=True)\n",
      "else:\n",
      "    meta_df.drop_duplicates(cols='index', take_last=True, inplace=True)\n",
      "del meta_df[\"index\"]\n",
      "cov_df = pd.read_csv(jn(meta_dir,\"163_vs_ref_3500_coverage.tsv\"),sep=\"\\t\",index_col=0)\n",
      "ucla_ids = meta_df.index.unique()\n",
      "chrom_length = pd.read_csv(eu(\"~/vervet_project/metadata/ref3500.tsv\"),sep=\"\\t\",index_col=0,squeeze=True,header=False)\n",
      "autosomes = [\"CAE\" + str(i) for i in range(1,30)]\n",
      "chromosomes = [\"CAE\" + str(i) for i in range(1,30)+[\"X\",\"Y\"]]\n",
      "#genetic map for colony SNPs\n",
      "map_fn = eu(\"~/vervet_project/data/map/vervet.map\")\n",
      "map_s = pd.read_csv(map_fn,usecols=[1,2,4],index_col=[0,1],squeeze=True)\n",
      "map_s.index = pd.MultiIndex.from_tuples([(\"CAE\"+str(x[0]),x[1]) for x in map_s.index])\n",
      "#gene annotations (2 alternative versions)\n",
      "def annot_cols_for_attributes(annot_df):\n",
      "    def attribute_dic(attr):\n",
      "        attr_ls = [x.split(' \"') for x in [el for el in attr.split('\"; ') if el != \" \"]]\n",
      "        attr_dic = {el[0]:el[1] for el in attr_ls}\n",
      "        return attr_dic\n",
      "    def get_value(dic,key):\n",
      "        try:\n",
      "            return dic[key]\n",
      "        except KeyError:\n",
      "            return np.nan\n",
      "    annot_df[\"attribute\"] =  annot_df[\"attribute\"].apply(attribute_dic)\n",
      "    keys = set().union(*[el.keys() for el in annot_df[\"attribute\"]])\n",
      "    for k in keys:\n",
      "        annot_df[k] = annot_df[\"attribute\"].apply(lambda dic: get_value(dic,k))\n",
      "    del annot_df[\"attribute\"]\n",
      "    return annot_df\n",
      "annot_dir = eu(\"~/vervet_project/data/annotation/Chlorocebus_sabaeus_1_1\")\n",
      "annot_mike_header = [\"chrom\",\"source\",\"feature\",\"start\",\"end\",\"score\",\"strand\",\"frame\",\"attribute\"]\n",
      "annot_mike = pd.read_csv(jn(annot_dir,\n",
      "                            \"ref_Chlorocebus_sabeus_1.1_top_level.coding_only.\"\n",
      "                            \"CHR_ALL.CLEAN.UNIQ_CAE.gtf\"),\n",
      "                         sep=\"\\t\",header=False,names=annot_mike_header)\n",
      "annot_mike = annot_cols_for_attributes(annot_mike)\n",
      "annot_mike.index = pd.MultiIndex.from_tuples(zip(annot_mike[\"chrom\"],annot_mike[\"start\"]))\n",
      "#annot_20140703 = pd.read_csv(jn(annot_dir,\n",
      "#                            \"ref_Chlorocebus_sabeus_1.1_top_level.20140703_CAE.gtf\"),\n",
      "#                         sep=\"\\t\",header=False,names=annot_mike_header)\n",
      "#annot_20140703 = annot_cols_for_attributes(annot_20140703)\n",
      "#annot_20140703.index = pd.MultiIndex.from_tuples(zip(annot_20140703[\"chrom\"],annot_20140703[\"start\"]))\n",
      "def make_gene_df(annot_df):\n",
      "    idx_tuples = []\n",
      "    ends = []\n",
      "    names = []\n",
      "    transcript_ids = []\n",
      "    protein_ids = []\n",
      "    for n, df in annot_df.groupby(\"gene_id\",sort=False):\n",
      "        idx_tuples.append((df.index[0][0],df[\"start\"].min()))\n",
      "        ends.append(df[\"end\"].max())\n",
      "        names.append(n)\n",
      "        transcript_ids.append(df.iloc[0][\"transcript_id\"])\n",
      "        protein_ids.append(df[df[\"feature\"]==\"CDS\"].iloc[0][\"protein_id\"])\n",
      "    gene_df = pd.DataFrame({\"eqsnd\":ends,\"gene_id\":names,\"transcript_id\":transcript_ids,\"protein_id\":protein_ids},\n",
      "                       index=pd.MultiIndex.from_tuples(idx_tuples))\n",
      "    gene_df.index.names = [\"chrom\",\"pos\"]\n",
      "    return gene_df\n",
      "#gene_df.to_csv(jn(meta_dir,\"annot_mike_genes.tsv\"),sep=\"\\t\")\n",
      "def load_gene_df():\n",
      "    gene_df = pd.read_csv(jn(meta_dir,\"annot_mike_genes.tsv\"),sep=\"\\t\",index_col = [0,1])\n",
      "    gene_df[\"start\"] = gene_df.index.droplevel(0).values\n",
      "    gene_df[\"length\"] = gene_df[\"end\"]-gene_df[\"start\"]\n",
      "    #reorder columns\n",
      "    cols = gene_df.columns.tolist()\n",
      "    cols = cols[-1:] + cols[:-1]\n",
      "    gene_df = gene_df[cols]\n",
      "    return gene_df\n",
      "gene_df = load_gene_df()\n",
      "#SIV candidates\n",
      "siv_candidates = [\"AKT1\",\"APOBEC3G\",\"APOBEC3H\",\"CCL2\",\"CCL7\",\"CCL11\",\"CCL3\",\"CCL5\",\"CCR2\",\"CCR3\",\n",
      " \"CCR5\",\"CD4\",\"CLEC4M\",\"CXCR1\",\"CXCR4\",\"DEFB1\",\"EIF2AK2\",\"ERAP2\",\"GML\",\n",
      " \"HLA-A\",\"HLA-B\",\"HLA-C\",\"IL4\",\"IRF7\",\"KIR\",\"PPIA\",\"PTPRC\",\"BST2\",\"TLR7\",\"TRIM5\",\"TSG101\"]\n",
      "\n",
      "def is_siv_candidate(row):\n",
      "    return (row[\"gene_id\"] in siv_candidates)\n",
      "\n",
      "def get_siv_candidate_df(gene_df):\n",
      "    return gene_df[gene_df.apply(is_siv_candidate,axis=1)]\n",
      "import pyfasta\n",
      "ref = pyfasta.Fasta(eu(\"~/vervet_project/data/reference/reference_3500/3500_indID1_codeVRC_ref_sequencer3_seqType1_filtered0_version6.fasta\"))\n",
      "def get_ref_seq(gene_id):\n",
      "    row = gene_df[gene_df[\"gene_id\"]==gene_id].iloc[0]\n",
      "    return ref[row.name[0]][row[\"start\"]:row[\"end\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Selection scans"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "find sweeD outlier regions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#THESE METHODS ARE CONFOUNDED BY GENE LENGTH, USE THE PERMUTATION METHOD IMPLEMENTED IN\n",
      "# test_enrichment.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def gene_likelihood_chrom(chrom):\n",
      "    \"\"\"\n",
      "    get max likelihood within each gene for all populations\n",
      "    \"\"\"\n",
      "    result_dic = {}\n",
      "    for pop in pops:\n",
      "        sweed_df = get_sweed_df(chrom,pop)\n",
      "        result_dic.update({pop:gene_likelihood(sweed_df)})\n",
      "    return result_dic\n",
      "\n",
      "def get_sweed_df(chrom,pop):\n",
      "    sweed_res = pd.read_csv(eu(\"~/vervet_project/analyses/20140611_163_subpop_sweepfinder/\"\n",
      "                             \"_data/SweeD_Report.163_ref3500_{}_{}\".format(chrom,pop)),\n",
      "                                                          sep=\"\\t\",skiprows=2,index_col=0)\n",
      "    sweed_res.index = pd.MultiIndex.from_tuples(zip([chrom]*len(sweed_res.index),sweed_res.index))\n",
      "    return sweed_res\n",
      "\n",
      "def gene_likelihood(outlier_locations,mode=\"max\"):\n",
      "    \"\"\"\n",
      "    get genes that overlap with the multi-index of the provided data frame\n",
      "    \"\"\"\n",
      "    modes = [\"max\",\"sum\"]\n",
      "    assert mode in modes\n",
      "    gene_hit_df = pd.DataFrame()\n",
      "    for chrom in outlier_locations.index.droplevel(1).unique():\n",
      "        pos_rel_to_start = gene_df.ix[chrom].index.searchsorted(outlier_locations.ix[chrom].index).values\n",
      "        pos_rel_to_end = np.searchsorted(gene_df.ix[chrom][\"end\"].values,outlier_locations.ix[chrom].index.values)\n",
      "        in_gene = (pos_rel_to_start - pos_rel_to_end) == 1\n",
      "        gene_hits = gene_df.ix[chrom].iloc[pos_rel_to_end[in_gene]]\n",
      "        gene_hits['chrom'] = chrom\n",
      "        gene_hits.set_index('chrom', append=True, inplace=True)\n",
      "        gene_hits = gene_hits.reorder_levels(['chrom', 'pos'])\n",
      "        gene_hits[\"likelihood\"] = outlier_locations[in_gene][\"Likelihood\"].values\n",
      "        gene_hit_df = gene_hit_df.append(gene_hits)\n",
      "    #if mode == \"max\":    \n",
      "    return gene_hit_df.groupby(lambda x:x).max()\n",
      "    #elif mode == \"sum\":\n",
      "    #    return gene_hit_df.groupby(lambda x:x).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reduce_gene_likelihood(res_ls):\n",
      "    total_res_dic = {}\n",
      "    for k in res_ls[0].keys():\n",
      "        total_res_dic.update({k:pd.concat([d[k] for d in res_ls])})\n",
      "    return total_res_dic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = lv.map_async(gene_likelihood_chrom,chromosomes)\n",
      "gene_likelihood_dic = reduce_gene_likelihood(res.result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = gene_likelihood_dic['sab']\n",
      "d = d.sort(\"length\",ascending=False)\n",
      "d[\"length_rank\"] = d.reset_index().index\n",
      "d = d.sort(\"likelihood\",ascending=False)\n",
      "d[\"likelihood_rank\"] = d.reset_index().index\n",
      "d[\"net_rank\"] = d[\"length_rank\"] - d[\"likelihood_rank\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(d[\"likelihood_rank\"],d[\"length_rank\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d.sort(\"length\")[\"gene_id\"].to_csv(jn(man_ana_dir,\"inverse_length_ranked_genes.txt\"),index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(d[\"likelihood\"],d[\"net_rank\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cand_dic = {}\n",
      "for k,v in gene_likelihood_dic.iteritems():\n",
      "    likelihood_df = v.sort(\"likelihood\",ascending=False).reset_index()\n",
      "    cand_dic.update({k:likelihood_df[likelihood_df.apply(get_candidates,axis=1)]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "1) maximum likelihood for each gene"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#rank the genes according to the max sweep likelihood\n",
      "for pop in pops:\n",
      "    gene_list = gene_likelihood_dic[pop].sort(\"likelihood\",ascending=False)[\"gene_id\"]\n",
      "    with open(jn(man_ana_dir,\"sweed_likelihood_ranked_genes_\"+pop+\".ls\"),\"w\") as f:\n",
      "        for line in gene_list:\n",
      "            f.write(line+\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#genes specific to each subspecies\n",
      "for pop0 in pops:\n",
      "    exclusive = gene_likelihood_dic[pop0]\n",
      "    for pop in [p for p in pops if p!=pop0]:\n",
      "        exclusive[\"likelihood\"] = exclusive[\"likelihood\"] - gene_likelihood_dic[pop][\"likelihood\"]\n",
      "    gene_list = exclusive.sort(\"likelihood\",ascending=False)[\"gene_id\"]\n",
      "    with open(jn(man_ana_dir,\"sweed_likelihood_ranked_genes_exclusive_to_\"+pop0+\".ls\"),\"w\") as f:\n",
      "        for line in gene_list:\n",
      "            f.write(line+\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#candidate genes: rankin when normalising  specific to each subspecies\n",
      "ex_cand_dic = {}\n",
      "for pop0 in pops:\n",
      "    exclusive = gene_likelihood_dic[pop0]\n",
      "    for pop in [p for p in pops if p!=pop0]:\n",
      "        exclusive[\"likelihood\"] = exclusive[\"likelihood\"] - gene_likelihood_dic[pop][\"likelihood\"]\n",
      "    exclusive = exclusive.sort(\"likelihood\",ascending=False).reset_index()\n",
      "    ex_cand_dic.update({pop0:exclusive[exclusive.apply(get_candidates,axis=1)]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "2) list of sites with highest likelihoods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def get_top_hits(chrom,sweed_df,top_n,min_dist=10000):\n",
      "    top_hits = pd.DataFrame()\n",
      "    exclude = np.array([])\n",
      "    for row in sweed_df.sort(\"Likelihood\",ascending=False).ix[chrom].iterrows():\n",
      "        #print np.absolute(exclude-row[0])>min_dist\n",
      "        #print row\n",
      "        if (np.absolute(exclude-row[0])>min_dist).all():\n",
      "            exclude = np.append(exclude,row[0])\n",
      "            top_hits = top_hits.append(pd.DataFrame(row[1]).T)\n",
      "        if len(top_hits) == top_n:\n",
      "            break\n",
      "    top_hits.index = pd.MultiIndex.from_tuples(zip([chrom]*top_n,top_hits.index))\n",
      "    top_hits.index.names = [\"chrom\", \"pos\"]\n",
      "    \n",
      "    return get_gene_info(top_hits)\n",
      "\n",
      "def get_top_hits_all_chrom(pop,top_n,min_dist=10000):\n",
      "    top_hits_ls = []\n",
      "    for chrom in chromosomes:\n",
      "        sweed_df = get_sweed_df(chrom,pop)\n",
      "        top_hits_ls.append(get_top_hits(chrom,sweed_df,top_n,min_dist=min_dist))\n",
      "    all_top_hits = pd.concat(top_hits_ls)\n",
      "    return all_top_hits.sort(\"Likelihood\",ascending=False)#.iloc[:top_n]\n",
      "\n",
      "def get_gene_info(hit_df):\n",
      "    \"\"\"\n",
      "    For each index location in hit_df add the location of the closest\n",
      "    gene to the data frame.\n",
      "    All entries in the df must be on the same chromosome.\n",
      "    \"\"\"\n",
      "    \n",
      "    hit_df = hit_df.copy()\n",
      "    chrom_ls = hit_df.index.droplevel(1).unique()\n",
      "    assert len(chrom_ls) == 1, \"Only implemented for data from single chromosome, but len(chrom_ls)=\" + str(len(chrom_ls))\n",
      "    chrom = chrom_ls[0]\n",
      "    loc_gene_df = gene_df.ix[chrom]\n",
      "    loc_gene_df = loc_gene_df.append(pd.DataFrame(np.nan,index=[inf],columns=loc_gene_df.columns))\n",
      "    pos_rel_to_start = loc_gene_df.index.searchsorted(hit_df.ix[chrom].index).values\n",
      "    pos_rel_to_end = np.searchsorted(loc_gene_df[\"end\"].values,hit_df.ix[chrom].index.values)\n",
      "    in_gene = (pos_rel_to_start - pos_rel_to_end) == 1\n",
      "    hit_df[\"in_gene_id\"] = np.nan\n",
      "    hit_df.ix[in_gene,\"in_gene_id\"] = loc_gene_df.iloc[pos_rel_to_end[in_gene]][\"gene_id\"].values\n",
      "    hit_df[\"in_gene_len\"] = np.nan\n",
      "    hit_df.ix[in_gene,\"in_gene_len\"] = loc_gene_df.iloc[pos_rel_to_end[in_gene]][\"end\"].values - \\\n",
      "                                        loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values\n",
      "    hit_df[\"in_gene_rel_pos\"] = np.nan\n",
      "    #print hit_df.ix[in_gene].ix[chrom].index.values - loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values\n",
      "    hit_df.ix[in_gene,\"in_gene_rel_pos\"] = ( hit_df.ix[in_gene].ix[chrom].index.values - \\\n",
      "                                            loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values)/\\\n",
      "                                            (loc_gene_df.iloc[pos_rel_to_end[in_gene]][\"end\"].values - \\\n",
      "                                             loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values)\n",
      "    \n",
      "    hit_df[\"upstream_gene_id\"] = loc_gene_df.iloc[pos_rel_to_end-1][\"gene_id\"].values\n",
      "    hit_df[\"upstream_gene_end_dist\"] = hit_df.ix[chrom].index.values  - loc_gene_df.iloc[pos_rel_to_end-1][\"end\"].values\n",
      "    hit_df[\"upstream_gene_len\"] = loc_gene_df.iloc[pos_rel_to_end-1][\"end\"].values - loc_gene_df.iloc[pos_rel_to_end-1].index.values\n",
      "    #print pos_rel_to_start\n",
      "    hit_df[\"downstream_gene_id\"] = loc_gene_df.iloc[pos_rel_to_start][\"gene_id\"].values\n",
      "    hit_df[\"downstream_gene_start_dist\"] = loc_gene_df.iloc[pos_rel_to_start].index.values - hit_df.ix[chrom].index.values\n",
      "    hit_df[\"downstream_gene_len\"] = loc_gene_df.iloc[pos_rel_to_start][\"end\"].values - \\\n",
      "                                        loc_gene_df.iloc[pos_rel_to_start].index.values\n",
      "    hit_df[\"closest_gene\"] = np.nan\n",
      "    hit_df.ix[in_gene,\"closest_gene\"] = hit_df.ix[in_gene,\"in_gene_id\"]\n",
      "    hit_df.ix[~in_gene,\"closest_gene\"] = (hit_df.ix[~in_gene,\"upstream_gene_end_dist\"] < \\\n",
      "                                          hit_df.ix[~in_gene,\"downstream_gene_start_dist\"])*hit_df.ix[~in_gene,\"upstream_gene_id\"] +\\\n",
      "                                         (hit_df.ix[~in_gene,\"upstream_gene_end_dist\"] >= \\\n",
      "                                          hit_df.ix[~in_gene,\"downstream_gene_start_dist\"])*hit_df.ix[~in_gene,\"downstream_gene_id\"]\n",
      "    return hit_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_hit_map = lv.map_async(lambda p: get_top_hits_all_chrom(p,top_n=20000,min_dist=50000),pops)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_hit_dic = {pop:r for pop,r in zip(pops,top_hit_map.get())}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for pop in pops:\n",
      "    top_hit_dic[pop][\"closest_gene\"].to_csv(jn(man_ana_dir,\"sweed_top5000_peaks_closest_genes_{}.txt\".format(pop)),index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = []\n",
      "for pop in pops:\n",
      "    s1 = top_hit_dic[pop].groupby(\"closest_gene\").apply(lambda r: r[\"Likelihood\"].max())\n",
      "    s1.name = pop\n",
      "    s.append(s1)\n",
      "likelihood_closest_hit_gene_all_pop = pd.concat(s,axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get genes that are positively selected in all populations\n",
      "zscores = likelihood_closest_hit_gene_all_pop.apply(lambda c: (c-c.mean())/c.std(ddof=0))\n",
      "total_normalised_likelhood_per_gene = zscores.sum(axis=1).sort(inplace=False,ascending=False)\n",
      "total_normalised_likelhood_per_gene.index.name = \"gene_id\"\n",
      "total_normalised_likelhood_per_gene.name = \"all_pop_likelihood\"\n",
      "len_s = gene_df.set_index(\"gene_id\")[\"length\"]\n",
      "total_normalised_likelhood_per_gene.reset_index()[\"gene_id\"].to_csv(jn(man_ana_dir,\"normalised_likelood_closest_gene_ranked_all_pop.txt\"),index=False)\n",
      "total_normalised_likelhood_per_gene = pd.concat([total_normalised_likelhood_per_gene,len_s],axis=1).sort(\"all_pop_likelihood\",ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pop = \"aet\"\n",
      "exclusive_zscore = zscores[pop] - zscores[[p for p in pops if p != pop]].sum(axis=1)*1./len([p for p in pops if p != pop])\n",
      "exclusive_zscore.name = \"zscore_exclusive\"\n",
      "exclusive_zscore.index.name = \"gene_id\"\n",
      "exclusive_zscore.ix[exclusive_zscore.notnull()].reset_index()\\\n",
      "            .sort(\"zscore_exclusive\",ascending=False)[\"gene_id\"]\\\n",
      "            .to_csv(jn(man_ana_dir,\"gene_sweep_likelihood_closest_exclusive_{}.txt\".format(pop)),index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Conclusion: the closest gene measure still has a correlation of r=0.3 with gene length"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(shared_top_hits[0],shared_top_hits[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pop = \"sab\"\n",
      "top_n = 1000\n",
      "top_hits_all_chrom =  get_top_hits_all_chrom(pop,top_n,min_dist=50000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Gene ontology enrichment permutation test"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "permutation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "\n",
      "def shift_sweed_df(tot_sweed_df,rnd):\n",
      "    new_start_i = int(len(tot_sweed_df)*rnd)\n",
      "    rotate_data = np.concatenate((tot_sweed_df.iloc[new_start_i:].values,tot_sweed_df.iloc[:new_start_i].values))\n",
      "    df = pd.DataFrame(rotate_data,index=tot_sweed_df.index,columns=tot_sweed_df.columns)\n",
      "    return df\n",
      "\n",
      "def index_rolling(s,window,func,overlap=0,*args,**kwargs):\n",
      "    \"\"\"\n",
      "    Apply function in rolling windows, where the window\n",
      "    size is defined with respect to the index values.\n",
      "    This means that different windows can comprise different\n",
      "    numbers of elements.\n",
      "    \n",
      "    s ... pandas Series\n",
      "    window ... window size in units of the index values\n",
      "    func ... function to apply to the series values within each\n",
      "                window\n",
      "    overlap ... oberlap size of windows\n",
      "    args, kwarg ... additional arguments for func\n",
      "    \"\"\"\n",
      "    #note that basis must be sorted in order for this to work properly\n",
      "    windows_min = s.index.min()\n",
      "    windows_max = s.index.max()\n",
      "    window_starts = np.arange(windows_min, windows_max, window-overlap)\n",
      "    window_starts = pd.Series(window_starts, index = window_starts)\n",
      "    def applyToWindow(val):\n",
      "        # using slice_indexer rather that what.loc [val:val+window] allows\n",
      "        # window limits that are not specifically in the index\n",
      "        indexer = s.index.slice_indexer(val,val+window,1)\n",
      "        chunk = s.iloc[indexer]\n",
      "        try:\n",
      "            return func(chunk,*args,**kwargs)\n",
      "        except ValueError, e:\n",
      "            if \"empty sequence\" in str(e):\n",
      "                #print indexer, chunk\n",
      "                return None\n",
      "            else:\n",
      "                raise           \n",
      "    rolled = window_starts.apply(applyToWindow)\n",
      "    return rolled\n",
      "\n",
      "def get_peaks(value_s,min_peak_dist):\n",
      "    assert len(value_s.index.droplevel(1).unique()) == 1\n",
      "    chrom = value_s.index[0][0]\n",
      "    x = index_rolling(value_s.ix[chrom],2*min_peak_dist,np.argmax,min_peak_dist)\n",
      "\n",
      "    x.name = \"pos\"\n",
      "    #only take peaks that are found in at least two windows \n",
      "    #this makes sure that we have a minimal distance between peaks\n",
      "    pos_true = (x.reset_index().groupby(\"pos\").apply(len)>1)\n",
      "    pos = pos_true[pos_true.values].index\n",
      "    s = value_s.ix[chrom].ix[pos]#.sort(inplace=False,ascending=False)\n",
      "    s.name = \"likelihood\"\n",
      "    return s\n",
      "\n",
      "\n",
      "\n",
      "def get_peak_genes_all_chrom(pop,shift_rand,min_peak_dist):\n",
      "    tot_sweed_df = pd.concat([get_sweed_df(chrom,pop) for chrom in chromosomes])\n",
      "    tot_sweed_df = shift_sweed_df(tot_sweed_df,shift_rand)\n",
      "    #group by chromosome\n",
      "    chrom_groups = tot_sweed_df[\"Likelihood\"].groupby(lambda x: x[0])\n",
      "    peaks = chrom_groups.apply(lambda df: get_peaks(df,min_peak_dist))\n",
      "    peaks.name = \"likelihood\"\n",
      "    df = get_gene_info(peaks).sort(\"likelihood\",ascending=False)\n",
      "    return df\n",
      "\n",
      "def get_gene_info(peak_s):\n",
      "    \"\"\"\n",
      "    take the input series and gets \n",
      "    \"\"\"\n",
      "    if not peak_s.index.is_monotonic:\n",
      "        peak_s = peak_s.sort_index()\n",
      "    tot_hit_df = pd.DataFrame()\n",
      "    for chrom in peak_s.index.droplevel(1).unique():\n",
      "        hit_df = pd.DataFrame(peak_s.ix[chrom])\n",
      "        loc_gene_df = gene_df.ix[chrom]\n",
      "        loc_gene_df = loc_gene_df.append(pd.DataFrame(np.nan,index=[inf],columns=loc_gene_df.columns))\n",
      "        pos_rel_to_start = loc_gene_df.index.searchsorted(peak_s.ix[chrom].index).values\n",
      "        pos_rel_to_end = np.searchsorted(loc_gene_df[\"end\"].values,peak_s.ix[chrom].index.values)\n",
      "        in_gene = (pos_rel_to_start - pos_rel_to_end) == 1\n",
      "        hit_df[\"in_gene_id\"] = \"\"\n",
      "\n",
      "        hit_df[\"in_gene_id\"][in_gene] = loc_gene_df.iloc[pos_rel_to_end[in_gene]][\"gene_id\"].values\n",
      "\n",
      "        hit_df[\"in_gene_len\"] = \"\"\n",
      "        hit_df[\"in_gene_len\"][in_gene] = loc_gene_df.iloc[pos_rel_to_end[in_gene]][\"end\"].values - \\\n",
      "                                            loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values\n",
      "        hit_df[\"in_gene_rel_pos\"] = np.nan\n",
      "        #print hit_df.ix[in_gene].ix[chrom].index.values - loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values\n",
      "\n",
      "        hit_df[\"in_gene_rel_pos\"][in_gene] = ( hit_df.ix[in_gene].index.values - \\\n",
      "                                                    loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values)/\\\n",
      "                                                    (loc_gene_df.iloc[pos_rel_to_end[in_gene]][\"end\"].values - \\\n",
      "                                                     loc_gene_df.iloc[pos_rel_to_end[in_gene]].index.values)\n",
      "\n",
      "        hit_df[\"upstream_gene_id\"] = loc_gene_df.iloc[pos_rel_to_end-1][\"gene_id\"].values\n",
      "        hit_df[\"upstream_gene_end_dist\"] = hit_df.index.values  - loc_gene_df.iloc[pos_rel_to_end-1][\"end\"].values\n",
      "        hit_df[\"upstream_gene_len\"] = loc_gene_df.iloc[pos_rel_to_end-1][\"end\"].values - loc_gene_df.iloc[pos_rel_to_end-1].index.values\n",
      "        #print pos_rel_to_start\n",
      "        hit_df[\"downstream_gene_id\"] = loc_gene_df.iloc[pos_rel_to_start][\"gene_id\"].values\n",
      "        hit_df[\"downstream_gene_start_dist\"] = loc_gene_df.iloc[pos_rel_to_start].index.values - hit_df.index.values\n",
      "        hit_df[\"downstream_gene_len\"] = loc_gene_df.iloc[pos_rel_to_start][\"end\"].values - \\\n",
      "                                            loc_gene_df.iloc[pos_rel_to_start].index.values\n",
      "        hit_df[\"closest_gene\"] = np.nan\n",
      "        #return hit_df, in_gene\n",
      "        hit_df[\"closest_gene\"].iloc[in_gene] = hit_df[\"in_gene_id\"].iloc[in_gene]\n",
      "        hit_df[\"closest_gene\"].iloc[~in_gene] = (hit_df[\"upstream_gene_end_dist\"].iloc[~in_gene] < \\\n",
      "                                              hit_df[\"downstream_gene_start_dist\"].iloc[~in_gene])*hit_df[\"upstream_gene_id\"].iloc[~in_gene] +\\\n",
      "                                             (hit_df[\"upstream_gene_end_dist\"].iloc[~in_gene] >= \\\n",
      "                                              hit_df[\"downstream_gene_start_dist\"].iloc[~in_gene])*hit_df[\"downstream_gene_id\"].iloc[~in_gene]\n",
      "        hit_df.index = pd.MultiIndex.from_tuples(zip([chrom]*len(hit_df),hit_df.index))\n",
      "        hit_df.index.names = [\"chrom\", \"pos\"]\n",
      "        tot_hit_df = pd.concat([tot_hit_df,hit_df])\n",
      "    c = tot_hit_df.columns\n",
      "    tot_hit_df = tot_hit_df[c[-1:]+c[:-1]]\n",
      "    return tot_hit_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "pop = \"sab\"\n",
      "tot_sweed_df = pd.concat([get_sweed_df(chrom,pop) for chrom in chromosomes])\n",
      "def get_peak_genes_tot_sweed_df(tot_sweed_df,shift_rand,min_peak_dist):\n",
      "    tot_sweed_df = shift_sweed_df(tot_sweed_df,shift_rand)\n",
      "    #group by chromosome\n",
      "    chrom_groups = tot_sweed_df[\"Likelihood\"].groupby(lambda x: x[0])\n",
      "    peaks = chrom_groups.apply(lambda df: get_peaks(df,min_peak_dist))\n",
      "    peaks.name = \"likelihood\"\n",
      "    df = get_gene_info(peaks).sort(\"likelihood\",ascending=False)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sab_peaks = get_peak_genes_tot_sweed_df(tot_sweed_df,shift_rand=0,min_peak_dist=50000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = lv.map_async(lambda rnd: get_peak_genes_tot_sweed_df(tot_sweed_df,shift_rand=rnd,min_peak_dist=50000),np.random.rand(500))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def empirical_p(value,dist):\n",
      "    array = np.append(value,dist)\n",
      "    temp = array.argsort()\n",
      "    ranks = np.empty(len(array), int)\n",
      "    ranks[temp] = np.arange(len(array))\n",
      "    return 1-(ranks[0])*1./len(array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def genes_per_go(go_df):\n",
      "    if len(set(go_df.index)) != len(go_df.index):\n",
      "        #remove secondary peaks for genes\n",
      "        go_df = go_df.groupby(lambda x:x).apply(lambda sdf: sdf.sort(\"likelihood\").iloc[0])\n",
      "    assert len(set(go_df.index)) == len(go_df.index)\n",
      "    s = pd.Series({\"genes\":list(go_df.index),\"likelihoods\":list(go_df[\"likelihood\"])})\n",
      "    return s\n",
      "\n",
      "def get_go_associations(top_hit_df,top_n):\n",
      "    genes = top_hit_df.set_index(\"closest_gene\").iloc[:top_n].join(gene_to_go.set_index(\"gene_symbol\")).groupby(\"go_identifier\").apply(genes_per_go)\n",
      "    #genes.name  = \"genes\"\n",
      "    assoc_df = pd.DataFrame(genes)\n",
      "    assoc_df[\"n_genes\"] = genes[\"genes\"].apply(len)\n",
      "    assoc_df.sort(\"n_genes\",inplace=True,ascending=False)\n",
      "    assoc_df = assoc_df.join(go_to_name.set_index(\"go_identifier\"))\n",
      "    assoc_df[\"mean_likelihood\"] = assoc_df[\"likelihoods\"].apply(lambda x: np.mean(x))\n",
      "    return assoc_df\n",
      "def get_go_counts(top_hit_df,top_n):\n",
      "    \n",
      "    #try:\n",
      "    counts = top_hit_df.set_index(\"closest_gene\").iloc[:top_n]\\\n",
      "                    .join(gene_to_go.set_index(\"gene_symbol\"))\\\n",
      "                        .groupby(\"go_identifier\").apply(genes_per_go)#.apply(len)\n",
      "    counts[\"genes\"] = counts[\"genes\"].apply(len)\n",
      "    counts[\"mean_likelihood\"] = counts[\"likelihoods\"].apply(np.mean)\n",
      "    del counts[\"likelihoods\"]\n",
      "    #except:\n",
      "    #    return top_n, top_hit_df\n",
      "    return counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "n_top = 10000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res2 = lv.map_async(lambda x: get_go_counts(x,n_top),res.result)\n",
      "result = res2.get()\n",
      "permut_assoc = pd.concat([r[\"genes\"] for r in result],axis=1).fillna(0)\n",
      "permut_likelihoods = pd.concat([r[\"mean_likelihood\"] for r in result],axis=1)\n",
      "quantile99 = permut_assoc.apply(lambda row: np.percentile(row,q=99),axis=1)\n",
      "mean = permut_assoc.mean(axis=1)\n",
      "median = permut_assoc.median(axis=1)\n",
      "assoc = get_go_associations(sab_peaks,n_top)\n",
      "assoc[\"control_mean_likelihood\"] = permut_likelihoods.mean(axis=1)\n",
      "assoc[\"quantile99\"] = quantile99\n",
      "assoc[\"mean\"] = mean\n",
      "assoc[\"median\"] = median\n",
      "assoc[\"above_99\"] = assoc[\"n_genes\"] - assoc[\"quantile99\"]\n",
      "sign_assoc = assoc[(assoc[\"above_99\"]>0)&(assoc[\"n_genes\"]>1)].sort(\"above_99\",ascending=False)\n",
      "sign_assoc.to_csv(jn(man_ana_dir,\"sweed_permutation_go_association_top_{}_sab.csv\".format(n_top)),sep=\";\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}